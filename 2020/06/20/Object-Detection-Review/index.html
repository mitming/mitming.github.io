<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Object Detection Review | Ming</title><meta name="keywords" content="Object Detection"><meta name="author" content="Ming Li"><meta name="copyright" content="Ming Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="什么是目标检测 计算机视觉领域有三个基本任务，分别是分类、检测和分割。如图所示。   分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其">
<meta property="og:type" content="article">
<meta property="og:title" content="Object Detection Review">
<meta property="og:url" content="https://coderming.cn/2020/06/20/Object-Detection-Review/index.html">
<meta property="og:site_name" content="Ming">
<meta property="og:description" content="什么是目标检测 计算机视觉领域有三个基本任务，分别是分类、检测和分割。如图所示。   分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/review.png">
<meta property="article:published_time" content="2020-06-20T07:46:57.000Z">
<meta property="article:modified_time" content="2020-06-25T13:21:53.021Z">
<meta property="article:author" content="Ming Li">
<meta property="article:tag" content="Object Detection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/review.png"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="https://coderming.cn/2020/06/20/Object-Detection-Review/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-06-25 21:21:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">33</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/images/"><i class="fa-fw fas fa-images"></i><span> Images</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg"></div><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="toc-number">1.</span> <span class="toc-text"> 什么是目标检测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text"> 目标检测现有方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95"><span class="toc-number">2.1.</span> <span class="toc-text"> 深度目标检测方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%BC%E8%BF%B0%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9"><span class="toc-number">2.1.1.</span> <span class="toc-text"> 综述(博客内容)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E6%A6%82%E6%8B%AC"><span class="toc-number">2.1.2.</span> <span class="toc-text"> 分类概括</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95"><span class="toc-number">2.1.3.</span> <span class="toc-text"> 关键技术发展</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="toc-number">2.2.</span> <span class="toc-text"> 传统目标检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="toc-number">2.3.</span> <span class="toc-text"> 深度目标检测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">3.</span> <span class="toc-text"> 数据集和评价指标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.1.</span> <span class="toc-text"> 数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">3.2.</span> <span class="toc-text"> 评价指标</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#iou"><span class="toc-number">3.2.1.</span> <span class="toc-text"> IoU</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tp-fp-fn-tn"><span class="toc-number">3.2.2.</span> <span class="toc-text"> TP、FP、FN、TN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%86%E7%A1%AE%E7%8E%87precision%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87recall"><span class="toc-number">3.2.3.</span> <span class="toc-text"> 准确率(Precision)和召回率(Recall)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pr%E6%9B%B2%E7%BA%BF"><span class="toc-number">3.2.4.</span> <span class="toc-text"> PR曲线</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#apaverage-precision"><span class="toc-number">3.2.5.</span> <span class="toc-text"> AP(Average Precision)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#map"><span class="toc-number">3.2.6.</span> <span class="toc-text"> mAP</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="toc-number">4.</span> <span class="toc-text"> 参考链接</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/review.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ming</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/images/"><i class="fa-fw fas fa-images"></i><span> Images</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Object Detection Review</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-06-20T07:46:57.000Z" title="Created 2020-06-20 15:46:57">2020-06-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-06-25T13:21:53.021Z" title="Updated 2020-06-25 21:21:53">2020-06-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Object-Detection/">Object Detection</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>9min</span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h2 id="什么是目标检测"><a class="markdownIt-Anchor" href="#什么是目标检测"></a> 什么是目标检测</h2>
<p>计算机视觉领域有三个基本任务，分别是分类、检测和分割。如图所示。<br />
<img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/classify_detection_segmentation.jpg" alt="" /></p>
<ol>
<li>分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其他任务提供了基础。在应用领域，人脸、场景的识别等都可以归为分类任务。</li>
<li>检测（Detection）。分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置），因而，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。</li>
<li>分割（Segmentation）。分割包括语义分割（semantic segmentation）和实例分割（instance segmentation），前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。</li>
</ol>
<h2 id="目标检测现有方法"><a class="markdownIt-Anchor" href="#目标检测现有方法"></a> 目标检测现有方法</h2>
<h3 id="深度目标检测方法"><a class="markdownIt-Anchor" href="#深度目标检测方法"></a> 深度目标检测方法</h3>
<h4 id="综述博客内容"><a class="markdownIt-Anchor" href="#综述博客内容"></a> 综述(博客内容)</h4>
<p><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/review.png" alt="" /></p>
<h4 id="分类概括"><a class="markdownIt-Anchor" href="#分类概括"></a> 分类概括</h4>
<p><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/methods_category.jpg" alt="" /></p>
<h4 id="关键技术发展"><a class="markdownIt-Anchor" href="#关键技术发展"></a> 关键技术发展</h4>
<p><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/methods.png" alt="" /></p>
<h3 id="传统目标检测"><a class="markdownIt-Anchor" href="#传统目标检测"></a> 传统目标检测</h3>
<p>传统检测方法一般分三个步骤：</p>
<ol>
<li>首先在给定图像上采用不同大小的滑动窗口(多尺度)对整幅图像进行遍历选择候选区域(ROI)，使用不同大小的滑动窗口框住待测图像中的某一部分作为候选区域，然后提取该候选区域相关的视觉特征。</li>
<li>特征提取，如人检测和普通目标检测常用的 HOG 和 SIFT 特征等，然后对这些区域提取特征。</li>
<li>分类器分类，即使用训练完成的分类器进行分类，如常用的SVM，最后使用分类器进行分类。</li>
</ol>
<p>传统方法的瓶颈在于：</p>
<ol>
<li>大量冗余的 proposal 生成，导致学习效率低下，容易在分类出现大量的假正样本。</li>
<li>特征描述子都是基于低级特征进行手工设计的，难以捕捉高级语义特征和复杂内容。</li>
<li>检测的每个步骤是独立的，缺乏一种全局的优化方案进行控制。</li>
</ol>
<h3 id="深度目标检测"><a class="markdownIt-Anchor" href="#深度目标检测"></a> 深度目标检测</h3>
<p>主要可以分为 One-Stage、Two-Stage 和 Anchor-Free 三类。</p>
<ol>
<li>Two-Stage：需要先提取 proposals/ROI，然后再对这些 ROI 进行分类和回归。</li>
<li>One-Stage：直接预测不同目标的类别与位置，不需要首先提取 ROI。</li>
<li>Anchor-Free：目前是预测图中每个物体的一个或多个关键点，利用这些关键点来预测最后的 Bounding Box。</li>
</ol>
<p>two-stage检测器包括两个步骤：</p>
<ol>
<li>使用 RPN 生成 anchor 并对 anchor 做筛选，过滤掉很多的负样本proposals，生成稀疏的proposals；</li>
<li>对得到的 proposals 进行分类和回归，对选择的 proposals，使用 roi pooling 等操作，进一步的精细化，因此得到的框更加精准。（比如，一个 anchor 有可能只覆盖了一个目标的50%，但却作为完全的正样本，因此其预测肯定是有误差的。）</li>
</ol>
<p>One-stage检测器步骤：<br />
在指定特征图上，对每个位置，使用不同 scale、不同长宽比密集采样生成 anchor（没有对这些 anchor 进行筛选），直接进行分类和回归。主要优点是计算效率高，但是，检测精度通常落后于 Two-stage 方法。</p>
<p>【One-stage精度低】：<br />
原因：<br />
主要原因是类别不均衡问题（因为没有对负类的anchor进行删除）。<br />
解决方案：<br />
为了改善类别不均衡问题，RetinaNet 提出了 Focal Loss 重建标准交叉熵损失，降低 easy sample 的权重，增加 hard sample 的权重。</p>
<p>【One-stage对小物体检测不好（没有Two-stage好）】：<br />
原因：<br />
如果所有的 anchor 都没有覆盖到这个目标，那么这个目标就会漏检。如果一个比较大的 anchor 覆盖了这个目标，那么较大的感受野会弱化目标的真实特征，得分也不会高。two-stage 算法中的 roi pooling 会对目标做 resize, 小目标的特征被放大，其特征轮廓也更为清晰，因此检测也更为准确。</p>
<p>解决方案：</p>
<ol>
<li>最直接的提升就是增大input size（但是不能一味的增大，因为会让后面的特征量增大，时间增多，失去One-stage的速度优势）</li>
<li>借鉴FPN，把深层特征通过反卷积，然后通过skip pooling来结合底层的特征层。（结合的方式上有： concat, pixel-wise sum/ add等）（这样做的好处是，只用 SSD 的话虽然用了底层特征图，但是底层语义特征比较弱，处理小物体时效果表现的不好）</li>
<li>空洞卷积增加感受野（TridentNet）</li>
<li>attention机制（One-stage中目前用的好像比较少）</li>
</ol>
<h2 id="数据集和评价指标"><a class="markdownIt-Anchor" href="#数据集和评价指标"></a> 数据集和评价指标</h2>
<h3 id="数据集"><a class="markdownIt-Anchor" href="#数据集"></a> 数据集</h3>
<ul>
<li><a target="_blank" rel="noopener" href="http://host.robots.ox.ac.uk/pascal/VOC/">Pascal VOC</a></li>
</ul>
<div class="hide-toggle" style="border: 1px solid  #D3D3D3"><div class="hide-button toggle-title" style="background-color:  #D3D3D3;"><i class="fas fa-caret-right fa-fw"></i><span>查看介绍</span></div>
    <div class="hide-content"><p>VOC数据集是目标检测经常用的一个数据集，自2005年起每年举办一次比赛，最开始只有4类，到2007年扩充为20个类，共有两个常用的版本：2007和2012。学术界常用5k的train/val 2007和16k的train/val 2012作为训练集，test 2007作为测试集，用10k的train/val 2007+test 2007和16k的train/val 2012作为训练集，test2012作为测试集，分别汇报结果。</p>
</div></div>
<ul>
<li><a target="_blank" rel="noopener" href="http://cocodataset.org/">MS COCO</a></li>
</ul>
<div class="hide-toggle" style="border: 1px solid  #D3D3D3"><div class="hide-button toggle-title" style="background-color:  #D3D3D3;"><i class="fas fa-caret-right fa-fw"></i><span>查看介绍</span></div>
    <div class="hide-content"><p>COCO数据集是微软团队发布的一个可以用来图像recognition+segmentation+captioning的数据集，该数据集收集了大量包含常见物体的日常场景图片，并提供像素级的实例标注以更精确地评估检测和分割算法的效果，致力于推动场景理解的研究进展。依托这一数据集，每年举办一次比赛，现已涵盖检测、分割、关键点识别、注释等机器视觉的中心任务，是继ImageNet Chanllenge以来最有影响力的学术竞赛之一。相比ImageNet，COCO更加偏好目标与其场景共同出现的图片，即non-iconic images。这样的图片能够反映视觉上的语义，更符合图像理解的任务要求。而相对的iconic images则更适合浅语义的图像分类等任务。COCO的检测任务共含有80个类，在2014年发布的数据规模分train/val/test分别为80k/40k/40k，学术界较为通用的划分是使用train和35k的val子集作为训练集（trainval35k），使用剩余的val作为测试集（minival），同时向官方的evaluation server提交结果（test-dev）。除此之外，COCO官方也保留一部分test数据作为比赛的评测集。</p>
</div></div>
<ul>
<li><a target="_blank" rel="noopener" href="https://storage.googleapis.com/openimages/web/index.html">Google Open Image</a></li>
</ul>
<div class="hide-toggle" style="border: 1px solid  #D3D3D3"><div class="hide-button toggle-title" style="background-color:  #D3D3D3;"><i class="fas fa-caret-right fa-fw"></i><span>查看介绍</span></div>
    <div class="hide-content"><p>pen Image是谷歌团队发布的数据集。最新发布的Open Images V4包含190万图像、600个种类，1540万个bounding-box标注，是当前最大的带物体位置标注信息的数据集。这些边界框大部分都是由专业注释人员手动绘制的，确保了它们的准确性和一致性。另外，这些图像是非常多样化的，并且通常包含有多个对象的复杂场景（平均每个图像 8 个）。</p>
</div></div>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.image-net.org">ImageNet</a></li>
</ul>
<div class="hide-toggle" style="border: 1px solid  #D3D3D3"><div class="hide-button toggle-title" style="background-color:  #D3D3D3;"><i class="fas fa-caret-right fa-fw"></i><span>查看介绍</span></div>
    <div class="hide-content"><p>ImageNet是一个计算机视觉系统识别项目， 是目前世界上图像识别最大的数据库。ImageNet是美国斯坦福的计算机科学家，模拟人类的识别系统建立的。能够从图片识别物体。Imagenet数据集文档详细，有专门的团队维护，使用非常方便，在计算机视觉领域研究论文中应用非常广，几乎成为了目前深度学习图像领域算法性能检验的“标准”数据集。Imagenet数据集有1400多万幅图片，涵盖2万多个类别；其中有超过百万的图片有明确的类别标注和图像中物体位置的标注。</p>
</div></div>
<ul>
<li><a target="_blank" rel="noopener" href="https://captain-whu.github.io/DOTA/dataset.html">DOTA数据集</a></li>
</ul>
<div class="hide-toggle" style="border: 1px solid  #D3D3D3"><div class="hide-button toggle-title" style="background-color:  #D3D3D3;"><i class="fas fa-caret-right fa-fw"></i><span>查看介绍</span></div>
    <div class="hide-content"><p>DOTA是遥感航空图像检测的常用数据集，包含2806张航空图像，尺寸大约为4kx4k，包含15个类别共计188282个实例，其中14个主类，small vehicle 和 large vehicle都是vehicle的子类。其标注方式为四点确定的任意形状和方向的四边形。航空图像区别于传统数据集，有其自己的特点，如：尺度变化性更大；密集的小物体检测；检测目标的不确定性。数据划分为1/6验证集，1/3测试集，1/2训练集。目前发布了训练集和验证集，图像尺寸从800x800到4000x4000不等。</p>
</div></div>
<h3 id="评价指标"><a class="markdownIt-Anchor" href="#评价指标"></a> 评价指标</h3>
<p>目标检测的主要评价指标就是 mAP (mean Average Precision), 即各类别 AP 的平均值</p>
<h4 id="iou"><a class="markdownIt-Anchor" href="#iou"></a> IoU</h4>
<p>交并比（IOU）是度量两个检测框（对于目标检测来说）的交叠程度，公式如下：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">O</mi><mi mathvariant="normal">U</mi></mrow><mo>=</mo><mfrac><mrow><mi mathvariant="normal">area</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>B</mi><mi>p</mi></msub><mo>∩</mo><msub><mi>B</mi><mrow><mi>g</mi><mi>t</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow><mrow><mi mathvariant="normal">area</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>B</mi><mi>p</mi></msub><mo>∪</mo><msub><mi>B</mi><mrow><mi>g</mi><mi>t</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\mathrm{IOU}=\frac{\operatorname{area}\left(B_{p} \cap B_{g t}\right)}{\operatorname{area}\left(B_{p} \cup B_{g t}\right)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathrm">I</span><span class="mord mathrm">O</span><span class="mord mathrm">U</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.399108em;vertical-align:-0.972108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">a</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28055599999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">a</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28055599999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.972108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>B</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">B_{p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 是预测的检测框，而 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>B</mi><mrow><mi>g</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">B_{g t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28055599999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 是真实的检测框(Ground Truth)。</p>
<h4 id="tp-fp-fn-tn"><a class="markdownIt-Anchor" href="#tp-fp-fn-tn"></a> TP、FP、FN、TN</h4>
<ol>
<li>True Positive (TP): IoU&gt;Threshold ( 一般取 0.5 ) 的检测框数量（同一 Ground Truth 只计算一次）</li>
<li>False Positive (FP): IoU&lt;= 的检测框数量，<strong>或者是检测到同一个 GT 的多余检测框的数量</strong></li>
<li>False Negative (FN): 没有检测到的 GT 的数量</li>
<li>True Negative (TN): 在 mAP 评价指标中不会使用到</li>
</ol>
<h4 id="准确率precision和召回率recall"><a class="markdownIt-Anchor" href="#准确率precision和召回率recall"></a> 准确率(Precision)和召回率(Recall)</h4>
<ol>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Precision = \frac{TP}{TP+FP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.275662em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Recall = \frac{TP}{TP+FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.275662em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
</ol>
<h4 id="pr曲线"><a class="markdownIt-Anchor" href="#pr曲线"></a> PR曲线</h4>
<p>由于 Precision 和 Recall 都是相对 Threshold 而改变的东西， 这是一场 Precision 与 Recall 之间的trade off， 用一组固定值表述不够全面， 因为我们根据不同的 threshold， 可以取到不同（也可能相同）的 Precision Recall 值。 这样想的话对于每个 threshold，我们都有 (Precision， Recall) 的 pair， 也就有了 Precision 和 Recall 之间的 curve 关系。</p>
<p><strong>对于每一个类</strong>, 每个预测框都有一个 score/confidence, 从大到小排序, 以此选择其 score 作为 threshold 来得到一组不同的 Precision 和 Recall, 这样如果一个类在所有图片中的预测框数量之和为 100 个, 那么就能得到 100 组 Precision 和 Recall, 根据这 100 组数据来画出 PR 曲线。</p>
<h4 id="apaverage-precision"><a class="markdownIt-Anchor" href="#apaverage-precision"></a> AP(Average Precision)</h4>
<p>对于一个类，其 AP 值为 PR 曲线下的面积，通常来说一个越好的分类器，AP 值越高。AP 可以充分的表示在这个模型中， Precision 和 Recall 的总体优劣。</p>
<h4 id="map"><a class="markdownIt-Anchor" href="#map"></a> mAP</h4>
<p>mAP 是多个类别 AP 的平均值。这个 mean 的意思是对每个类的 AP 值再求平均，得到的就是 mAP 的值，mAP 的大小一定在 [0,1] 区间，越大越好。该指标是目标检测算法中最重要的一个。</p>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/53405779/answer/429585383">知乎-陳子豪</a><br />
<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247484121&amp;idx=1&amp;sn=d29803cf9d76f8ff3b781b1d898eb6f3&amp;chksm=9f80b84fa8f731590e35ae64800866deba3a7383c7668f4b0f68078b6d5a2954e923b7b4f465&amp;scene=21#wechat_redirect">微信公众号- GiantPandaCV</a></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Ming Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://coderming.cn/2020/06/20/Object-Detection-Review/">https://coderming.cn/2020/06/20/Object-Detection-Review/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Object-Detection/">Object Detection</a></div><div class="post_share"><div class="social-share" data-image="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/review.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://limingcv.coding.net/p/images/d/images/git/raw/master/reward/wechat.png" target="_blank"><img class="post-qr-code-img" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/reward/wechat.png" alt="WeChat"/></a><div class="post-qr-code-desc">WeChat</div></li><li class="reward-item"><a href="https://qr.alipay.com/fkx12431y6k0soy7vokzi19" target="_blank"><img class="post-qr-code-img" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/reward/alipay.jpg" alt="AliPay"/></a><div class="post-qr-code-desc">AliPay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/06/20/One-Stage-Object-Detection/"><img class="prev-cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/One-Stage-Object-Detection/cover.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">One-Stage Object Detection</div></div></a></div><div class="next-post pull-right"><a href="/2020/06/16/Lightweight-Network/"><img class="next-cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Lightweight-Network/ghost_bottleneck.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Lightweight Network</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/08/27/Object-Detection-with-NAS/" title="Object Detection with NAS"><img class="cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_pipeline.png"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-27</div><div class="title">Object Detection with NAS</div></div></a></div><div><a href="/2020/09/01/Weakly-Supervised-Object-Detection/" title="Weakly Supervised Object Detection"><img class="cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/09/Weakly-Supervised-Object-Detection/avatar.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-01</div><div class="title">Weakly Supervised Object Detection</div></div></a></div><div><a href="/2020/09/29/Introduction-To-Visual-Tracking/" title="Introduction to Visual Tracking"><img class="cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/09/Introduction-To-Visual-Tracking/avatar.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-29</div><div class="title">Introduction to Visual Tracking</div></div></a></div></div></div></article></main><footer id="footer" style="background-image: url(https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/06/Object-Detection-Review/review.png)"><div id="footer-wrap"><div class="copyright">&copy;2020 By Ming Li</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script></div></div></body></html>