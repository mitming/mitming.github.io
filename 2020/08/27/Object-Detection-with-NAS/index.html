<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Object Detection with NAS | Ming</title><meta name="keywords" content="NAS"><meta name="author" content="Ming Li"><meta name="copyright" content="Ming Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="DetNASIdeaObject detectors are usually equipped with backbone networks designed for image classification, but there is a gap between the tasks of image classification and object detection, so it might">
<meta property="og:type" content="article">
<meta property="og:title" content="Object Detection with NAS">
<meta property="og:url" content="https://coderming.cn/2020/08/27/Object-Detection-with-NAS/index.html">
<meta property="og:site_name" content="Ming">
<meta property="og:description" content="DetNASIdeaObject detectors are usually equipped with backbone networks designed for image classification, but there is a gap between the tasks of image classification and object detection, so it might">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_pipeline.png">
<meta property="article:published_time" content="2020-08-27T04:17:36.000Z">
<meta property="article:modified_time" content="2020-10-18T08:19:18.904Z">
<meta property="article:author" content="Ming Li">
<meta property="article:tag" content="NAS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_pipeline.png"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="https://coderming.cn/2020/08/27/Object-Detection-with-NAS/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-10-18 16:19:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">19</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">14</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/images/"><i class="fa-fw fas fa-images"></i><span> Images</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg"></div><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#DetNAS"><span class="toc-number">1.</span> <span class="toc-text">DetNAS</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Idea"><span class="toc-number">1.1.</span> <span class="toc-text">Idea</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Contribution"><span class="toc-number">1.2.</span> <span class="toc-text">Contribution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Framework-Overview"><span class="toc-number">1.3.</span> <span class="toc-text">Framework Overview</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Difficulties-for-searching-backbone"><span class="toc-number">1.4.</span> <span class="toc-text">Difficulties for searching backbone</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Backbone-Search"><span class="toc-number">1.5.</span> <span class="toc-text">Backbone Search</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Motivation"><span class="toc-number">1.5.1.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NAS-Pipeline"><span class="toc-number">1.5.2.</span> <span class="toc-text">NAS Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Search-Space"><span class="toc-number">1.5.3.</span> <span class="toc-text">Search Space</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Results"><span class="toc-number">1.6.</span> <span class="toc-text">Results</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Ablation-Studies"><span class="toc-number">1.6.1.</span> <span class="toc-text">Ablation Studies</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Comparisons-to-random-search"><span class="toc-number">1.6.2.</span> <span class="toc-text">Comparisons to random search</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#NAS-FPN"><span class="toc-number">2.</span> <span class="toc-text">NAS-FPN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Idea-1"><span class="toc-number">2.1.</span> <span class="toc-text">Idea</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Contribution-1"><span class="toc-number">2.2.</span> <span class="toc-text">Contribution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Merging-Cell"><span class="toc-number">2.3.</span> <span class="toc-text">Merging Cell</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FPN"><span class="toc-number">2.4.</span> <span class="toc-text">FPN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Early-Exit"><span class="toc-number">2.5.</span> <span class="toc-text">Early Exit</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Results-1"><span class="toc-number">2.6.</span> <span class="toc-text">Results</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_pipeline.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ming</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/images/"><i class="fa-fw fas fa-images"></i><span> Images</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Object Detection with NAS</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-08-27T04:17:36.000Z" title="Created 2020-08-27 12:17:36">2020-08-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-18T08:19:18.904Z" title="Updated 2020-10-18 16:19:18">2020-10-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Object-Detection/">Object Detection</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">1.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>10min</span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="DetNAS"><a href="#DetNAS" class="headerlink" title="DetNAS"></a>DetNAS</h1><h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><p>Object detectors are usually equipped with backbone networks designed for image classification, but there is a gap between the tasks of image classification and object detection, so it might be a sub-optimal choice.</p>
<p>Train the one-shot supernet under the typical detector training schedule:</p>
<ol>
<li>ImageNet pre-training</li>
<li>Detection fine-tuning</li>
</ol>
<p>Then the architecture search is performed on the trained supernet, using the detection task as the guidance to search better backbone.</p>
<h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ol>
<li>The first paper use NAS to search backbone for object detection</li>
<li>Proposed a powerful search space to help searched networks obtain inspiring accuracies with limited FLOPs</li>
<li>Outperforms the hand-crafted networks</li>
<li>Solve the problem that searching backbone for object detection with NAS could be hard to optimize and inefficient.</li>
</ol>
<h2 id="Framework-Overview"><a href="#Framework-Overview" class="headerlink" title="Framework Overview"></a>Framework Overview</h2><ol>
<li>Pre-training the one-shot supernet on ImageNet</li>
<li>Fine-tuning the one-shot supernet on detection datasets</li>
<li>architecture search on the trained supernet with an evolution algorithm</li>
</ol>
<p><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_pipeline.png"></p>
<h2 id="Difficulties-for-searching-backbone"><a href="#Difficulties-for-searching-backbone" class="headerlink" title="Difficulties for searching backbone"></a>Difficulties for searching backbone</h2><ol>
<li><strong>hard to optimize</strong><br>NAS systems require accuracies on target tasks as signals, pre-training accuracy is unqualified for this requirement.</li>
<li><strong>inefficiency</strong><br>In order to obtain the precious performance, each candidate architecture during search has to be first pre-trained(e.g. on ImageNet) then fine-tuned on the detection dataset, which is very costly.</li>
</ol>
<p>The difficulties mainly caused by the typical detector training schedule that requires backbone networks to be pre-trained on ImageNet. Even though training from scratch is an alternative, it requires more training iterations to compensate for the lack of pre-training. Moreover, training from scratch breaks down in small datasets.</p>
<h2 id="Backbone-Search"><a href="#Backbone-Search" class="headerlink" title="Backbone Search"></a>Backbone Search</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>The search space $A$ can be denoted by a DAG, any path in the graph corresponds to a specific architecture, $a \in A$. For the specific architecture, its corresponding network can be represented as $N(a, w)$ with the backbone network weight $w$.</p>
<p>NAS aims to find the optimal backbone architecture $a^* \in A$ that minimizes the validation loss $\mathcal{L}<em>{val}(N(a^*, w^*))$, $w^*$ denotes the optimal backbone network weights of the backbone architecture $a^*$. It is obtained by minimizes the training loss. Then the NAS process can be regarded as a nested optimization problem:<br>$$\begin{array}{c}<br>\min <em>{a \in \mathcal{A}} \mathcal{L}</em>{v a l}\left(\mathcal{N}\left(a, w^{<em>}(a)\right)\right) \quad<br>\text { s.t. } w^{</em>}(a)=\underset{w}{\arg \min } \mathcal{L}</em>{t r a i n}(w, a)<br>\end{array}\tag{1}$$</p>
<p>The above formulation can represent NAS on tasks that work without pre-training(e.g. image classification), but for object detection, which needs pre-training and fine-tuning schedule, <code>Eq.(1)</code> needs to be reformulated as follow:<br>$$\begin{array}{c}<br>\min <em>{a \in \mathcal{A}} \mathcal{L}</em>{v a l}\left(\mathcal{N}\left(a, w^{<em>}(a)\right)\right) \<br>w^{</em>}(a)=\underset{w \leftarrow w_{p}(a)^{<em>}}{\arg \min } \mathcal{L}<em>{\text {train}}^{\text {det}}(w, a) \quad \text { s.t. } w</em>{p}(a)^{</em>}=\underset{w_{p}}{\arg \min } \mathcal{L}<em>{\text {train}}^{c l s}\left(w</em>{p}, a\right) \tag{2}<br>\end{array}$$</p>
<p>where $w \leftarrow w_{p}(a)^{<em>}$ is to optimize $w$ with $w_p(a)^</em>$ as initialization. The pre-trained backbone weights $w_p(a)^*$ on ImageNet cannot directly serve for the <code>Eq.(1)</code>, but it is necessary for $w(a)^{<em>}$, thus we can not skip the ImageNet pre-training. However, ImageNet pre-training usually cost several GPU days just for a single network. It is unaffordable to train all candidate networks individually, in one-shot NAS methods, search space is encoded in a supernet consists of all candidate architectures, sharing the weights in their common nodes, in this way, <code>Eq.(1)</code> become:<br>$$\min <em>{a \in \mathcal{A}} \mathcal{L}</em>{\text {val}}\left(\mathcal{N}\left(a, W_{\mathcal{A}}^{</em>}(a)\right)\right) \quad \text { s.t. } W_{\mathcal{A}}^{*}=\underset{W}{\arg \min } \mathcal{L}_{\text {train}}(\mathcal{N}(\mathcal{A}, W)) \tag{3}$$</p>
<p>where all individual network weights $w(a)$ are inherited from the one-shot supernet $W_{A}$. <strong>The process of training supernet ($W_A$ optimization) is decoupled from the process of searching architecture ($a$ optimization).</strong> Combine <code>Eq.(2)</code> and <code>Eq.(3)</code> can get the final representation:<br>$$\begin{array}{l}<br>\min <em>{a \in \mathcal{A}} \mathcal{L}</em>{v a l}^{\operatorname{det}}\left(\mathcal{N}\left(a, W_{\mathcal{A}}^{<em>}(a)\right)\right) \<br>\text { s.t. } W_{\mathcal{A}}^{</em>}=\underset{W \leftarrow W_{p \mathcal{A}}^{<em>}}{\arg \min } \mathcal{L}<em>{\text {train}}^{\text {det}}(\mathcal{N}(\mathcal{A}, W)) \<br>W</em>{p \mathcal{A}}^{</em>}=\arg \min <em>{W</em>{p}} \mathcal{L}<em>{\text {train}}^{c l s}\left(\mathcal{N}\left(\mathcal{A}, W</em>{p}\right)\right)<br>\end{array}$$</p>
<h3 id="NAS-Pipeline"><a href="#NAS-Pipeline" class="headerlink" title="NAS Pipeline"></a>NAS Pipeline</h3><ol>
<li>Supernet pre-training</li>
</ol>
<p><strong>pre-training supernet on ImageNet</strong> and <strong>adopt a path-wise manner</strong> to make sure the trained supernet can reflect the relative performance of candidate networks. Specifically, in each iteration, only one single path is sampled for forward and backward propagation. No gradient or weight update acts on other paths or nodes in the super graph.<br>2. Supernet fine-tuning<br>The supernet fine-tuning is also <strong>path-wise</strong> but <strong>equipped with detection heads and metrics and datasets</strong>. Another important detail is <strong>using Synchronized Batch Normalization instead of Batch Normalization during supernet training</strong>.<br>Typically the parameters of BN, during fine-tuning are fixed as the pre-training batch statistics, but the freezing BN is infeasible in DetNAS because the features to normalize are not equal on different paths, On the other hand, Object detection usually with small batch size.<br>3. Search on supernet with EA<br>This part is also about BN for detail, during training, different child networks are sampled path-wise in the supernet. The issue is that the batch statistics on one path should be independent of others.Therefore, we need to recompute batch statistics for each single path (child networks) before each evaluation. This detail is indispensable in DetNAS</p>
<h3 id="Search-Space"><a href="#Search-Space" class="headerlink" title="Search Space"></a>Search Space</h3><p><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_search_space.png"></p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="Ablation-Studies"><a href="#Ablation-Studies" class="headerlink" title="Ablation Studies"></a>Ablation Studies</h3><p><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_ablation_study.png"></p>
<ul>
<li>ShuffleNet is a baseline.</li>
<li><strong>ClsNASNet</strong> is the best backbone architecture searched on ImageNet but not using fine-tuning</li>
<li><strong>DetNAS-scratch</strong> means training supernet from scratch on detection datasets instead of pre-training on ImageNet</li>
<li><strong>DetNAS</strong>, as said, pre-training on ImageNet and fine-tuning on detection datasets.</li>
</ul>
<p>The ablation study shows that both pre-training and fine-tuning are important.</p>
<h3 id="Comparisons-to-random-search"><a href="#Comparisons-to-random-search" class="headerlink" title="Comparisons to random search"></a>Comparisons to random search</h3><p><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_results_compare_to_random_search.png"><br>It shows that EA are outperform than random search…but why use EA rather than gradient-based/RL methods? Another confusion is what’s the necessity of ablation study on search strategy in object detection papers???</p>
<h1 id="NAS-FPN"><a href="#NAS-FPN" class="headerlink" title="NAS-FPN"></a>NAS-FPN</h1><h2 id="Idea-1"><a href="#Idea-1" class="headerlink" title="Idea"></a>Idea</h2><p>PANet shows adding an extra bottom-up pathway on FPN features improves feature representations for lower resolution features.  So searching FPN maybe a good way to improve the performance of detectors.</p>
<p>The most difficult problem of searching feature architecture is its huge search space. The number of possible connections to combine features from different scales grow up exponentially with the number of layers. </p>
<p>So inspired by NASNet, NAS-FPN propose a search space of scalable architecture to generate, specifically, like NASNet, searching an atomic architecture(same input and output levels) and then stack(repeat) them to a large architecture.</p>
<h2 id="Contribution-1"><a href="#Contribution-1" class="headerlink" title="Contribution"></a>Contribution</h2><ol>
<li>Designed a search space that covers all possible cross-scale connections to generate multi-scale features.</li>
<li>The searched NAS-FPN architecture can be applied repeatedly like NASNet, so it is manageable and can achieve “early exit”.</li>
<li>Using scalable search space and NAS can tradeoff accuracy and speed.</li>
</ol>
<h2 id="Merging-Cell"><a href="#Merging-Cell" class="headerlink" title="Merging Cell"></a>Merging Cell</h2><p>Merging cell is a fundamental building block of a FPN, to merge any two input features layers into a output layer. A FPN consists of N(given during search) merging cells, in a merging cell, all feature layers have the same number of filters.  The decisions of how to conduct the merging cell are made by a controller RNN, each merging cell has 4 prediction steps made by distinct softmax classifier:</p>
<ol>
<li>Select a feature $h_i$ from candidates.</li>
<li>Select another feature $h_j$ from candidates.</li>
<li>Select the output feature resolution.</li>
<li>Select a operation to combine $h_i$ and $h_j$ and generate a feature layer with the resolution selected in Step 3.<br><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/TODO.png"></li>
</ol>
<p>There are two binary operations for Step 3, including sum and global pooling:<br><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/TODO.png"></p>
<p>Then the newly-generated feature layer is appended to the list of existing input candidates and become a new candidate for the next merging cell. There can be multiple candidate features share the same resolution during the search.</p>
<p>The order of output feature is predicted by the controller RNN, each output feature layer is then generated by repeating the step 1~4 until the output feature pyramid is fully generated.</p>
<p>In the end, the last 5 merging cells are designed to output feature pyramid ${ { P_3, P_4, P_5, P_6, P_7 } }$, taking all feature layers that have not been connected to any of output layer and sum them to the output layer that has the corresponding resolution.</p>
<h2 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h2><p>Basically follow the design of RetinaNet, which uses the last layer in each group of feature layers as the inputs to first pyramid network. <strong>For scalable NAS-FPN, the output of the first pyramid network are the input to the next pyramid network.</strong></p>
<p>Since both inputs and outputs of a NAS-FPN are feature layers in the identical scales, so the NAS-FPN can be stacked repeatedly for better accuracy.<br><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/TODO.png"></p>
<h2 id="Early-Exit"><a href="#Early-Exit" class="headerlink" title="Early Exit"></a>Early Exit</h2><p>We can attach classifier and box regression heads after all intermediate pyramid networks and train it with deep supervision. During inference, the model dose not need to finish the forward pass for all pyramid networks, Instead, it can stop at the output of any pyramid network and generate detection results.</p>
<p>This can be a desirable property when computation resource or latency is concerned.</p>
<h2 id="Results-1"><a href="#Results-1" class="headerlink" title="Results"></a>Results</h2><p>To show results, define <code>R-50, 5@256</code> for a model with backbone ResNet-50, 5 stacked NAS-FPN and 256 feature dimensions.</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Ming Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://coderming.cn/2020/08/27/Object-Detection-with-NAS/">https://coderming.cn/2020/08/27/Object-Detection-with-NAS/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NAS/">NAS</a></div><div class="post_share"><div class="social-share" data-image="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_pipeline.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://limingcv.coding.net/p/images/d/images/git/raw/master/reward/wechat.png" target="_blank"><img class="post-qr-code-img" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/reward/wechat.png" alt="WeChat"/></a><div class="post-qr-code-desc">WeChat</div></li><li class="reward-item"><a href="https://qr.alipay.com/fkx12431y6k0soy7vokzi19" target="_blank"><img class="post-qr-code-img" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/reward/alipay.jpg" alt="AliPay"/></a><div class="post-qr-code-desc">AliPay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/09/01/Weakly-Supervised-Object-Detection/"><img class="prev-cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/09/Weakly-Supervised-Object-Detection/avatar.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Weakly Supervised Object Detection</div></div></a></div><div class="next-post pull-right"><a href="/2020/08/04/NAS-Survey/"><img class="next-cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/NAS-Survey/nas_review.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Network Architecture Search Survey</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/08/04/NAS-Survey/" title="Network Architecture Search Survey"><img class="cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/NAS-Survey/nas_review.png"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-04</div><div class="title">Network Architecture Search Survey</div></div></a></div><div><a href="/2020/07/20/NAS/" title="Network Architecture Search"><img class="cover" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/07/NAS/avatar.png"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-20</div><div class="title">Network Architecture Search</div></div></a></div></div></div></article></main><footer id="footer" style="background-image: url(https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/08/Object-Detection-with-NAS/detnas_pipeline.png)"><div id="footer-wrap"><div class="copyright">&copy;2020 By Ming Li</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div></div></body></html>