<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Ming</title><meta name="author" content="Ming Li"><meta name="copyright" content="Ming Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta property="og:type" content="website">
<meta property="og:title" content="Ming">
<meta property="og:url" content="https://coderming.cn/page/3/index.html">
<meta property="og:site_name" content="Ming">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://coderming.cn/img/avatar.jpg">
<meta property="article:author" content="Ming Li">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://coderming.cn/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="https://coderming.cn/page/3/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isSidebar: false,
  postUpdate: '2020-12-14 12:37:57'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">42</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/images/"><i class="fa-fw fas fa-images"></i><span> Images</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg"></div><header class="full_page" id="page-header" style="background-image: url(https://limingcv.coding.net/p/images/d/images/git/raw/master/gallary/anime/13.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ming</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/images/"><i class="fa-fw fas fa-images"></i><span> Images</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site-title">Ming</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="mailto:limingcv@qq.com" target="_blank" title=""><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout_page" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/30/RubiksNet/" title="RubiksNet:Learnable 3D-Shift for Efficient Video Action Recognition">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/RubiksNet/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RubiksNet:Learnable 3D-Shift for Efficient Video Action Recognition"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/30/RubiksNet/" title="RubiksNet:Learnable 3D-Shift for Efficient Video Action Recognition">RubiksNet:Learnable 3D-Shift for Efficient Video Action Recognition</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-30T05:54:32.000Z" title="Created 2020-10-30 13:54:32">2020-10-30</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-30T11:33:59.000Z" title="Updated 2020-10-30 19:33:59">2020-10-30</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">这篇文章算是 TSM 的 follow up, TSM 那篇文章中 shift 哪些通道是自己手工设定的, 这篇文章想让网络自己去学习 shift 哪些通道, 另外 TSM 只在 temporal 维度上 shift channels, 而这里在 T,H,WT, H, WT,H,W 上都 shift channels.
 Introduction
虽然 TSM 通过在时序维度上 shift channels 来减少计算量, 但作者认为 TSM 模块的效率仍然会受限于空间操作中的参数和计算量, 所以想在 HHH 和 WWW 维度也对 channel 进行 shift, 即这篇文章不但把 shift channels 的操作拓展到了空间上(H and W), 而且还把 hand-designed fixed temporal shift 变成了 learnable unfixed spatiotemporal shift, 可以从名字上直观地看出把 hand-designed →\rightarrow→ learnable, fixed →\rightarrow→ unfixed, tem ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/29/TEA/" title="TEA:Temporal Excitation and Aggregation for Action Recognition">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/TEA/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TEA:Temporal Excitation and Aggregation for Action Recognition"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/29/TEA/" title="TEA:Temporal Excitation and Aggregation for Action Recognition">TEA:Temporal Excitation and Aggregation for Action Recognition</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-29T12:13:32.000Z" title="Created 2020-10-29 20:13:32">2020-10-29</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-12-07T08:43:21.000Z" title="Updated 2020-12-07 16:43:21">2020-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">论文: TEA: Temporal Excitation and Aggregation for Action Recognition
开源代码: https://github.com/Phoenix1327/tea-action-recognition
作者认为动作识别的时序建模需要同时考虑 short-range motions 和 long-range aggregations. 我的理解是需要同时考虑时序维度上的局部信息(short-range)和全局信息(long-range). 这篇文章提出了 2 种模块来分别对这 2 种信息建模, 以较低的 FLOPs 实现了比较好的效果.
 Introduction
对于 short-range 的动作建模, 大部分使用光流来做, 但这非常的耗费计算时间和存储空间, 此外这种 two-stream 的方法其时间特征和空间特征的学习是互相独立的, 而且只在 late layers 才进行融合. 所以作者提出了个 ME 模块, 直接使用特征之差来作为 motion 的表示, 而不是用光流来作为 motion 的表征.
对于 long-ran ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/29/TSM/" title="TSM:Temporal Shift Module for Efficient Video Understanding">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/TSM/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TSM:Temporal Shift Module for Efficient Video Understanding"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/29/TSM/" title="TSM:Temporal Shift Module for Efficient Video Understanding">TSM:Temporal Shift Module for Efficient Video Understanding</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-29T12:13:32.000Z" title="Created 2020-10-29 20:13:32">2020-10-29</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-12-07T08:46:00.000Z" title="Updated 2020-12-07 16:46:00">2020-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">论文: TSM:Temporal Shift Module for Efficient Video Understanding
开源代码: https://github.com/mit-han-lab/temporal-shift-module
韩松老师组的作品, 论文地址, 开源代码
这篇工作也是如何进行更加高效的 video understanding, 通过提出的 TSM 模块在维持 2D CNN 复杂度的情况下实现了 3D CNN 的精度. 具体做法是在时序维度随机 shift 一部分通道, 这种做法可以以 0 参数和 0 计算量增长的方式插入到任意 2D CNN 中, 作者还把 TSM 用到了 online setting 和 video object detection 中, 均取得了很好的效果.
 Introduction
通过使用 TSM 来在时序维度上 shift channels, 能够将相邻帧的信息混合到当前帧, 本文的思想是一个卷积操作应该是 shift + multiply-accumulate (即卷积的相乘再相加), 而非传统卷积的 multiply-ac ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/27/TPN/" title="Temporal Pyramid Network">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/TPN/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Temporal Pyramid Network"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/27/TPN/" title="Temporal Pyramid Network">Temporal Pyramid Network</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-27T12:13:32.000Z" title="Created 2020-10-27 20:13:32">2020-10-27</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-12-07T08:44:09.000Z" title="Updated 2020-12-07 16:44:09">2020-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">论文: Temporal Pyramid Network for Action Recognition
开源代码: https://github.com/decisionforce/TPN
这篇文章算是 SlowFast 的 follow up, SlowFast 可以看成是时序上的图像金字塔, 这篇文章提出的 TPN 可以看做是空间特征金字塔 + 时序特征金字塔, 图像金字塔是为了对不同尺度的物体进行建模, 而时序上的金字塔是为了对不同时序尺度(速度)的动作进行更好的建模. (注意加粗的字, 图像金字塔和特征金字塔是不一样的哦)
 Introduction
作者首先把动作的动态表示和时序尺度称为 “visual tempo”, 换句话说就是不同 action 在时序上的尺度和变化是不一致的, 如果能够对 visual tempo 进行建模就能帮助更好地进行动作识别.
visual tempo 的定义如下图所示

具体的计算方式是用一个 2D CNN 来计算每一帧的类别概率, 构造其分布, 直觉地, 如果一个动作很慢, 那么帧之间的差异就会越小, 即帧之间的类别概率也会越相似, 所以曲 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/27/X3D/" title="X3D:Expanding Architectures for Efficient Video Recognition">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/X3D/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="X3D:Expanding Architectures for Efficient Video Recognition"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/27/X3D/" title="X3D:Expanding Architectures for Efficient Video Recognition">X3D:Expanding Architectures for Efficient Video Recognition</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-27T12:13:32.000Z" title="Created 2020-10-27 20:13:32">2020-10-27</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-12-07T08:46:24.000Z" title="Updated 2020-12-07 16:46:24">2020-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">论文: X3D: Expanding Architectures for Efficient Video Recognition
开源代码: https://github.com/facebookresearch/SlowFast/tree/master/projects/x3d
EfficientNet 在 2D 图像分类中一骑绝尘, 让大家看到了可以通过拓展不同维度来实现效率和精度的 trade-off 的可能性, 本文的想法是把 2D CNN 在不同维度上进行缩放从而得到更加高效的 3D CNN, 可以通过控制缩放的因子来实现效率和精度的权衡, 和 EfficientNet 思路不同的是, 这里并非先用 NAS 搜一个 3D CNN, 而是直接对 2D CNN 进行缩放, 如下图所示.

 Introduction
可以缩放的维度包括以下几种:

时序持续时间 γt\gamma_{t}γt​
frame rate(采样间隔) γτ\gamma_{\tau}γτ​
空间分辨率 γs\gamma_{s}γs​
网络宽度(通道数) γw\gamma_{w}γw​
瓶颈层宽度 γb\ga ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/27/SlowFast/" title="SlowFast">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/SlowFast/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SlowFast"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/27/SlowFast/" title="SlowFast">SlowFast</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-27T09:06:32.000Z" title="Created 2020-10-27 17:06:32">2020-10-27</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-12-07T08:43:30.000Z" title="Updated 2020-12-07 16:43:30">2020-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">论文: SlowFast Networks for Video Recognition
开源代码: https://github.com/facebookresearch/SlowFast
 Introduction
提出了 SlowFast 模型, 如下图所示

上面的 path 为 slow path, 有更低的 frame rate, 更高的 channel 数, 主要用于捕捉空间上的语义信息, 下面的 path 为 fast path, 有更高的 frame rate, 更少的 channel 数, 主要用于捕获细粒度时序分辨率上的动作. Fast path 可以通过减少模型的通道数来实线轻量化. 整个模型可以看成是时序金字塔, 有点类似于图像金字塔, 区别是这里时序上的尺度只有 2 个, 一个 slow, 一个 fast, CVPR 2020 的 TPN 把时序金字塔拓展为了时序特征金字塔, 并添加了空间特征金字塔来进一步提升精度. 图像金字塔是为了对不同尺度的物体进行建模, 而时序上的金字塔是为了对不同时序尺度(速度)的动作进行更好的建模.
 SlowFast Networ ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/26/Multigrid-Training/" title="Multigrid Training">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/Multigrid-Training/grid_schedule.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Multigrid Training"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/26/Multigrid-Training/" title="Multigrid Training">Multigrid Training</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-26T02:06:32.000Z" title="Created 2020-10-26 10:06:32">2020-10-26</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-27T12:12:36.000Z" title="Updated 2020-10-27 20:12:36">2020-10-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">论文地址
开源代码
目前视频模型的训练通常是 follow 图像模型的训练过程, 即有着固定的 mini-batch data shape: 特定数目的 clips, frames 以及空间大小
但这种 shape 是最优的吗? 通常来说高分辨率(时间和空间维度上)的模型训练慢, 但精度高, 低分辨率的模型训练快但精度低, 收到数值优化中 multigrid 方法的启发, 本文提出使用可变的 mini-batch shapes, 即根据一种采样策略来在训练时改变 mini-batch 中的时空分辨率, 也就是改变 mini-batch 中数据的 shape, 在减少时间和空间维度的同时改变 mini-batch 的大小以及学习率大小, 以这种方式来加速训练.
 Introduction
对于 3D CNN 来说, 训练时优化器每次迭代会处理一个 mini-batch 的数据, 这个 mini-batch 里面的数据的形状 B×T×H×WB \times T \times H \times WB×T×H×W 在整个训练过程中都是固定的(CCC 忽略不用管), 有一些方法试图通过增大这些维 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Ming Li</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">42</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">15</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">8</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/mitming"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:limingcv@qq.com" target="_blank" title=""><i class="fas fa-envelope"></i></a></div></div></div><div class="sticky_layout"><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">Welcome to my blog! All formulas can be copied to LaTex format !</div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2020/12/12/CorrNet/" title="Video Modeling with Correlation Networks"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/CorrNet/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Video Modeling with Correlation Networks"/></a><div class="content"><a class="title" href="/2020/12/12/CorrNet/" title="Video Modeling with Correlation Networks">Video Modeling with Correlation Networks</a><time datetime="2020-12-12T09:13:32.000Z" title="Created 2020-12-12 17:13:32">2020-12-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/12/correlation_methods/" title="Architecture Design for Modeling Motion"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/Architecture_Design_For_Modeling_Motion/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Architecture Design for Modeling Motion"/></a><div class="content"><a class="title" href="/2020/12/12/correlation_methods/" title="Architecture Design for Modeling Motion">Architecture Design for Modeling Motion</a><time datetime="2020-12-12T07:18:32.000Z" title="Created 2020-12-12 15:18:32">2020-12-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/10/MotionSqueeze/" title="MotionSqueeze:Neural Motion Feature Learning for Video Understanding"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/MSNet/MSModule.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MotionSqueeze:Neural Motion Feature Learning for Video Understanding"/></a><div class="content"><a class="title" href="/2020/12/10/MotionSqueeze/" title="MotionSqueeze:Neural Motion Feature Learning for Video Understanding">MotionSqueeze:Neural Motion Feature Learning for Video Understanding</a><time datetime="2020-12-10T13:22:32.000Z" title="Created 2020-12-10 21:22:32">2020-12-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/10/CIDC/" title="Directional Temporal Modeling for Action Recognition"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/CIDC/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Directional Temporal Modeling for Action Recognition"/></a><div class="content"><a class="title" href="/2020/12/10/CIDC/" title="Directional Temporal Modeling for Action Recognition">Directional Temporal Modeling for Action Recognition</a><time datetime="2020-12-10T07:52:32.000Z" title="Created 2020-12-10 15:52:32">2020-12-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/10/Teporal_Distinct_Representation_Learning/" title="Temporal Distinct Representation Learning for Action Recognition"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/TDRL/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Temporal Distinct Representation Learning for Action Recognition"/></a><div class="content"><a class="title" href="/2020/12/10/Teporal_Distinct_Representation_Learning/" title="Temporal Distinct Representation Learning for Action Recognition">Temporal Distinct Representation Learning for Action Recognition</a><time datetime="2020-12-10T05:52:32.000Z" title="Created 2020-12-10 13:52:32">2020-12-10</time></div></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>Categories</span></div><ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Adversarial/"><span class="card-category-list-name">Adversarial</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/BN/"><span class="card-category-list-name">BN</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Backbone/"><span class="card-category-list-name">Backbone</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NAS/"><span class="card-category-list-name">NAS</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Object-Detection/"><span class="card-category-list-name">Object Detection</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Tracking/"><span class="card-category-list-name">Tracking</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Ubuntu/"><span class="card-category-list-name">Ubuntu</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Video/"><span class="card-category-list-name">Video</span><span class="card-category-list-count">25</span></a></li>
            
            </ul></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Action/" style="font-size: 1.5em; color: #99a9bf">Action</a> <a href="/tags/Adversarial/" style="font-size: 1.18em; color: #999ca1">Adversarial</a> <a href="/tags/Anchor-Free/" style="font-size: 1.1em; color: #999">Anchor Free</a> <a href="/tags/BN/" style="font-size: 1.1em; color: #999">BN</a> <a href="/tags/Backbone/" style="font-size: 1.1em; color: #999">Backbone</a> <a href="/tags/Detection/" style="font-size: 1.18em; color: #999ca1">Detection</a> <a href="/tags/Efficient/" style="font-size: 1.42em; color: #99a6b7">Efficient</a> <a href="/tags/NAS/" style="font-size: 1.26em; color: #999fa8">NAS</a> <a href="/tags/Object-Detection/" style="font-size: 1.34em; color: #99a3b0">Object Detection</a> <a href="/tags/One-Stage/" style="font-size: 1.1em; color: #999">One-Stage</a> <a href="/tags/Tracking/" style="font-size: 1.1em; color: #999">Tracking</a> <a href="/tags/Two-Stage/" style="font-size: 1.1em; color: #999">Two-Stage</a> <a href="/tags/Ubuntu/" style="font-size: 1.1em; color: #999">Ubuntu</a> <a href="/tags/Video/" style="font-size: 1.5em; color: #99a9bf">Video</a> <a href="/tags/Weakly-Supervised/" style="font-size: 1.1em; color: #999">Weakly Supervised</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">December 2020</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/11/"><span class="card-archive-list-date">November 2020</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/10/"><span class="card-archive-list-date">October 2020</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/09/"><span class="card-archive-list-date">September 2020</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/08/"><span class="card-archive-list-date">August 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/07/"><span class="card-archive-list-date">July 2020</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/06/"><span class="card-archive-list-date">June 2020</span><span class="card-archive-list-count">8</span></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">42</div></div><div class="webinfo-item"><div class="item-name">Total Count :</div><div class="item-count">159.6k</div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2020-12-14T04:37:56.711Z"></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://limingcv.coding.net/p/images/d/images/git/raw/master/gallary/anime/13.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 By Ming Li</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "If not me&#44; then who?,If not now&#44; then when?".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = 'If not me&#44; then who?'
  }
}

if (true) {
  if (typeof Typed === 'function') subtitleType()
  else $.getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js', subtitleType)
} else {
  subtitleType()
}</script></div></div></body></html>