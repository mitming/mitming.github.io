<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Ming</title><meta name="author" content="Ming Li"><meta name="copyright" content="Ming Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta property="og:type" content="website">
<meta property="og:title" content="Ming">
<meta property="og:url" content="https://coderming.cn/page/4/index.html">
<meta property="og:site_name" content="Ming">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://coderming.cn/img/avatar.jpg">
<meta property="article:author" content="Ming Li">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://coderming.cn/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="https://coderming.cn/page/4/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isSidebar: false,
  postUpdate: '2020-12-14 12:37:57'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">42</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/images/"><i class="fa-fw fas fa-images"></i><span> Images</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg"></div><header class="full_page" id="page-header" style="background-image: url(https://limingcv.coding.net/p/images/d/images/git/raw/master/gallary/anime/13.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ming</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/images/"><i class="fa-fw fas fa-images"></i><span> Images</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site-title">Ming</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="mailto:limingcv@qq.com" target="_blank" title=""><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout_page" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/24/Devils-in-BatchNorm/" title="Devils in BatchNorm">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/Devils-in-BatchNorm/bn.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Devils in BatchNorm"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/24/Devils-in-BatchNorm/" title="Devils in BatchNorm">Devils in BatchNorm</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-24T03:12:40.000Z" title="Created 2020-10-24 11:12:40">2020-10-24</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-25T02:01:14.000Z" title="Updated 2020-10-25 10:01:14">2020-10-25</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/BN/">BN</a></span></div><div class="content">先看下普通的 BN, 在 batch 上对所有的 channel 做 normalization, 把下图中的蓝色部分 norm 为 0 均值 1 方差, 在 normalization 后还加了一个 channel-wise 的 affine 层, 可以看成是一个非常退化的卷积层, 加了后精度会稍微好点, 因为网络更深了, 但本质上没有影响.

对于 BN 来说, 最重要的还是 train 和 test 时的不一致性. 这种不一致性是由 BN 本身的定义导致的:
μB,σB2= mean, var⁡(x, axis =[N,H,W])\mu_{B}, \sigma_{B}^{2}=\text { mean, } \operatorname{var}(x, \text { axis }=[N, H, W])
μB​,σB2​= mean, var(x, axis =[N,H,W])

Training time:

x^=x−μBσB\hat{x}=\frac{x-\mu_{B}}{\sigma_{B}}
x^=σB​x−μB​​
μEMA←λμEMA+(1−λ)μB\mu_{EMA} ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/21/Action-Recognition/" title="Action Recognition">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/Action-Recognition/timeline.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Action Recognition"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/21/Action-Recognition/" title="Action Recognition">Action Recognition</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-21T07:15:40.000Z" title="Created 2020-10-21 15:15:40">2020-10-21</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-29T08:59:52.000Z" title="Updated 2020-10-29 16:59:52">2020-10-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">这篇博客是根据 [CVPR 2020 Tutorial] 来整理有关行为识别的论文及方法. 一些方法的时间线如下:

最开始用 CNN 来做 Video 的是单流方法, 即只对 RGB frames 进行建模, 叫做 DeepVideo

但这种方法的效果并不是特别的好, 传统的手工特征 IDT 在 UCF101 数据集上的准确率为 87.9%, DeepVideo 的准确率才 65.4%, 可以看到这种方法只考虑了外观信息(整幅图片+中心位置), 没有对时序信息进行建模.



方法
UCF101




IDT
87.9%


DeepVideo
65.4%



所以自然而然地出现了同时对空间和时间进行建模的方法, Two-Stream Networks

上面的数据流的输入是 RGB frames, 对外观信息(空间)进行建模, 下面的数据流的输入是光流, 用于对时序信息进行建模, 假设一个视频共有 TTT 帧, 那么光流的图片数为 2×(T−1)2 \times (T-1)2×(T−1), 分别有 x,yx, yx,y 这 2 个空间方向.



方法
UCF101




 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/19/Introduction-to-Video-Action-Understanding/" title="Introduction to Video Action Understanding">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/Introduction-to-Video-Action-Understanding/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Introduction to Video Action Understanding"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/19/Introduction-to-Video-Action-Understanding/" title="Introduction to Video Action Understanding">Introduction to Video Action Understanding</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-19T02:23:32.000Z" title="Created 2020-10-19 10:23:32">2020-10-19</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-20T13:24:42.299Z" title="Updated 2020-10-20 21:24:42">2020-10-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content"> Introduction
本文主要是对 Video Action Understanding: A Tutorial 一文进行翻译和整理, 这是一篇很好的综述文章, MIT 大佬写的, 推荐去看.
首先说明一下几个概念, 在文献中 instance 通常是指一个动作实例, segment 是指从一个视频中裁剪出的一个片段.
作者把视频行为理解分为了下图中的几个部分:

 Problem Definition
 Action Recognition
定义为对一个完整的视频进行分类的过程, 如果动作在整个视频中都存在, 那么被称为 trimmed action recognition, 否则被称为 untrimmed action recognition, 通常而言 untrimmed action recognition 会更难, 因为此时模型需要在完成分类任务的同时忽略非动作的背景片段.

 Action Prediction
定义为对一个不完整的视频进行分类的过程, 即只知道视频的一部分, 用这一部分信息来对整个视频进行分类.

 Temporal Action Proposal
 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/12/Deformable-CNNs/" title="Deformable Convolutional Networks">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/Deformable-CNNs/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Deformable Convolutional Networks"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/12/Deformable-CNNs/" title="Deformable Convolutional Networks">Deformable Convolutional Networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-12T02:32:32.000Z" title="Created 2020-10-12 10:32:32">2020-10-12</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-12T05:05:12.604Z" title="Updated 2020-10-12 13:05:12">2020-10-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Backbone/">Backbone</a></span></div><div class="content"> Deformable CNN v1
Jifeng Dai 大佬在 MSRA 的工作, 在检测和分割领域应用很多, 思想也是非常值得学习.
 Introduction
对于视觉任务, 我们需要保持特征对于图片的旋转, 平移以及尺度的不变性, 举例就是对于图像分类任务, 对于同样的目标在不同图像中的偏移，旋转，尺度，要输出同样的结果。一些手工设计的特征(SIFT, SURF等)有一定的能力, 但显然无法利用 CNN 来实现 end-to-end 的设计.
CNN 通过池化层来实现平移不变性, 网络越深其效果越好, 但这种方式仍然受到卷积核以及感受野大小的限制, 但对于尺度不变性和旋转不变性几乎是没有的, 对于目标检测, 语义分割等任务可以使用特征金字塔(用来近似代替图像金字塔)来得到一定的尺度不变性, 旋转不变性就只能通过数据增强来实现.
一句话来说就是 网络模型对于物体几何形变的适应能力几乎完全来自于数据本身所具有的多样性。
这篇文章想解决的问题就是如何对 CNN 进行变化, 使其具有对物体的几何形变有适应能力. 要解决问题首先需要明白为什么会有这个问题, 卷积本身就是一种非常固定的几 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/02/Action-Recognition-Paper-List/" title="Action Recognition Paper List">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/Action-Recognition-Paper-List/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Action Recognition Paper List"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/02/Action-Recognition-Paper-List/" title="Action Recognition Paper List">Action Recognition Paper List</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-02T11:16:32.000Z" title="Created 2020-10-02 19:16:32">2020-10-02</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-29T08:59:39.000Z" title="Updated 2020-10-29 16:59:39">2020-10-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content">基本知识大家去看 Justin Johnson 开的 EECS 498-007 / 598-005: Deep Learning for Computer Vision 这门公开课就好啦
这里就直接上近 2 年的顶会论文了
 ECCV’20
AR-Net: Adaptive Frame Resolution for Eﬃcient Action Recognition
    想法是为输入中的每个帧即时选择最佳的分辨率, 以此来有效识别长的未裁剪的视频. 具体的, 对于给定给定视频帧, 用一个 policy network 替分类网络决定使用多大的分辨率, 这个 policy network 是和分类网络一起联合使用反向传播来训练的.
Pipeline 如下:

估计作者和我一样, 缺卡, 所以没跑整个 Kinetics 数据集.



DDGCN: A Dynamic Directed Graph Convolutional Network for Action Recognition
    利用图卷积和骨架信息来进行动作识别, 涉及到骨架的方法等用到骨架的时候再看吧, 先跳过.
 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/01/Action-Localization-Paper-List/" title="Action Localization Paper List">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/10/Action-Localization-Paper-List/temporal_action_localization.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Action Localization Paper List"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/01/Action-Localization-Paper-List/" title="Action Localization Paper List">Action Localization Paper List</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-10-01T07:14:32.000Z" title="Created 2020-10-01 15:14:32">2020-10-01</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-29T08:59:36.000Z" title="Updated 2020-10-29 16:59:36">2020-10-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Video/">Video</a></span></div><div class="content"> Overview
 Definition
首先介绍动作检测的基本知识, 后面会对这几年的顶会论文进行分析和结果展示.先看下动作检测和视频分类有什么区别吧.

动作分类就是视频分类, 判断视频中的物体在做啥, 动作检测就是给定一段长的视频, 不但要检测出有哪些动作, 还要检测这些动作开始和结束的时间.
 Recent Methods
主要分为 Anchor-Based 和 Anchor-Free


Anchor-Based
又叫 top-town 网络, 主要靠的是全局的上下文信息, 需要和检测中一样, 定义多尺度的 anchor 作为 proposals, 代表的方法有 SSAD, SSTAD, CBR, TURN 等


Anchor-Free
又叫 bottom-up 网络, 主要靠局部的上下文信息, 首先评估类似边界概率或者动作能力, 然后利用这些来生成 proposals, 代表的方法有 TAG 和 BSN 等.


 Paper Reading
 CVPR’20
ActionBytes: Learning From Trimmed Videos to Localize A ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/09/29/Introduction-To-Visual-Tracking/" title="Introduction to Visual Tracking">     <img class="post_bg" src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/09/Introduction-To-Visual-Tracking/avatar.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Introduction to Visual Tracking"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/09/29/Introduction-To-Visual-Tracking/" title="Introduction to Visual Tracking">Introduction to Visual Tracking</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-09-29T11:47:57.000Z" title="Created 2020-09-29 19:47:57">2020-09-29</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-02T09:24:24.327Z" title="Updated 2020-10-02 17:24:24">2020-10-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Tracking/">Tracking</a></span></div><div class="content"> Basic Knowledge
模型主要分为2大类: 生成和判别, 目前最火的是判别方法,  即 tracking-by-detection.


生成类方法
在当前帧对目标区域建模，下一帧寻找与模型最相似的区域就是预测位置，比较著名的有卡尔曼滤波，粒子滤波，mean-shift 等。举个例子，从当前帧知道了目标区域80%是红色，20%是绿色，然后在下一帧，搜索算法就像无头苍蝇，到处去找最符合这个颜色比例的区域


判别类方法
CV中的经典套路图像特征+机器学习， 当前帧以目标区域为正样本，背景区域为负样本，机器学习方法训练分类器，下一帧用训练好的分类器找最优区域


与生成类方法最大的区别，是分类器训练过程中用到了背景信息，这样分类器就能专注区分前景和背景，所以判别类方法普遍都比生成类好。
以下内容主要是对文章 Deep Learning for Visual Tracking: A Comprehensive Survey 进行翻译和自行整理.
 发现

SNN-based 方法最受欢迎, 因为能很好满足速度和精度上的 trade-off
最近的方法尝试用 RL 和 GAN 来  ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/3/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/5/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Ming Li</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">42</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">15</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">8</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/mitming"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:limingcv@qq.com" target="_blank" title=""><i class="fas fa-envelope"></i></a></div></div></div><div class="sticky_layout"><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">Welcome to my blog! All formulas can be copied to LaTex format !</div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2020/12/12/CorrNet/" title="Video Modeling with Correlation Networks"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/CorrNet/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Video Modeling with Correlation Networks"/></a><div class="content"><a class="title" href="/2020/12/12/CorrNet/" title="Video Modeling with Correlation Networks">Video Modeling with Correlation Networks</a><time datetime="2020-12-12T09:13:32.000Z" title="Created 2020-12-12 17:13:32">2020-12-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/12/correlation_methods/" title="Architecture Design for Modeling Motion"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/Architecture_Design_For_Modeling_Motion/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Architecture Design for Modeling Motion"/></a><div class="content"><a class="title" href="/2020/12/12/correlation_methods/" title="Architecture Design for Modeling Motion">Architecture Design for Modeling Motion</a><time datetime="2020-12-12T07:18:32.000Z" title="Created 2020-12-12 15:18:32">2020-12-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/10/MotionSqueeze/" title="MotionSqueeze:Neural Motion Feature Learning for Video Understanding"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/MSNet/MSModule.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MotionSqueeze:Neural Motion Feature Learning for Video Understanding"/></a><div class="content"><a class="title" href="/2020/12/10/MotionSqueeze/" title="MotionSqueeze:Neural Motion Feature Learning for Video Understanding">MotionSqueeze:Neural Motion Feature Learning for Video Understanding</a><time datetime="2020-12-10T13:22:32.000Z" title="Created 2020-12-10 21:22:32">2020-12-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/10/CIDC/" title="Directional Temporal Modeling for Action Recognition"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/CIDC/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Directional Temporal Modeling for Action Recognition"/></a><div class="content"><a class="title" href="/2020/12/10/CIDC/" title="Directional Temporal Modeling for Action Recognition">Directional Temporal Modeling for Action Recognition</a><time datetime="2020-12-10T07:52:32.000Z" title="Created 2020-12-10 15:52:32">2020-12-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/10/Teporal_Distinct_Representation_Learning/" title="Temporal Distinct Representation Learning for Action Recognition"><img src="https://limingcv.coding.net/p/images/d/images/git/raw/master/posts/2020/12/TDRL/avatar.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Temporal Distinct Representation Learning for Action Recognition"/></a><div class="content"><a class="title" href="/2020/12/10/Teporal_Distinct_Representation_Learning/" title="Temporal Distinct Representation Learning for Action Recognition">Temporal Distinct Representation Learning for Action Recognition</a><time datetime="2020-12-10T05:52:32.000Z" title="Created 2020-12-10 13:52:32">2020-12-10</time></div></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>Categories</span></div><ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Adversarial/"><span class="card-category-list-name">Adversarial</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/BN/"><span class="card-category-list-name">BN</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Backbone/"><span class="card-category-list-name">Backbone</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NAS/"><span class="card-category-list-name">NAS</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Object-Detection/"><span class="card-category-list-name">Object Detection</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Tracking/"><span class="card-category-list-name">Tracking</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Ubuntu/"><span class="card-category-list-name">Ubuntu</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Video/"><span class="card-category-list-name">Video</span><span class="card-category-list-count">25</span></a></li>
            
            </ul></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Action/" style="font-size: 1.5em; color: #99a9bf">Action</a> <a href="/tags/Adversarial/" style="font-size: 1.18em; color: #999ca1">Adversarial</a> <a href="/tags/Anchor-Free/" style="font-size: 1.1em; color: #999">Anchor Free</a> <a href="/tags/BN/" style="font-size: 1.1em; color: #999">BN</a> <a href="/tags/Backbone/" style="font-size: 1.1em; color: #999">Backbone</a> <a href="/tags/Detection/" style="font-size: 1.18em; color: #999ca1">Detection</a> <a href="/tags/Efficient/" style="font-size: 1.42em; color: #99a6b7">Efficient</a> <a href="/tags/NAS/" style="font-size: 1.26em; color: #999fa8">NAS</a> <a href="/tags/Object-Detection/" style="font-size: 1.34em; color: #99a3b0">Object Detection</a> <a href="/tags/One-Stage/" style="font-size: 1.1em; color: #999">One-Stage</a> <a href="/tags/Tracking/" style="font-size: 1.1em; color: #999">Tracking</a> <a href="/tags/Two-Stage/" style="font-size: 1.1em; color: #999">Two-Stage</a> <a href="/tags/Ubuntu/" style="font-size: 1.1em; color: #999">Ubuntu</a> <a href="/tags/Video/" style="font-size: 1.5em; color: #99a9bf">Video</a> <a href="/tags/Weakly-Supervised/" style="font-size: 1.1em; color: #999">Weakly Supervised</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">December 2020</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/11/"><span class="card-archive-list-date">November 2020</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/10/"><span class="card-archive-list-date">October 2020</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/09/"><span class="card-archive-list-date">September 2020</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/08/"><span class="card-archive-list-date">August 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/07/"><span class="card-archive-list-date">July 2020</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/06/"><span class="card-archive-list-date">June 2020</span><span class="card-archive-list-count">8</span></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">42</div></div><div class="webinfo-item"><div class="item-name">Total Count :</div><div class="item-count">159.6k</div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2020-12-14T04:37:56.711Z"></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://limingcv.coding.net/p/images/d/images/git/raw/master/gallary/anime/13.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 By Ming Li</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "If not me&#44; then who?,If not now&#44; then when?".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = 'If not me&#44; then who?'
  }
}

if (true) {
  if (typeof Typed === 'function') subtitleType()
  else $.getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js', subtitleType)
} else {
  subtitleType()
}</script></div></div></body></html>